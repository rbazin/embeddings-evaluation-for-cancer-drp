{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Notebook of Trained DRP Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from joblib import Parallel, delayed\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchmetrics.functional.regression import (\n",
    "    pearson_corrcoef,\n",
    "    spearman_corrcoef,\n",
    "    mean_squared_error,\n",
    "    mean_absolute_error,\n",
    ")\n",
    "from tqdm import tqdm\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "from src import DrugResponseDataset\n",
    "from src import (\n",
    "    DrugResponseModelTokens,\n",
    "    DrugResponseModelLegacy,\n",
    "    DrugResponseLightningModule,\n",
    ")\n",
    "\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles_embeddings_path = os.path.join(\"data\", \"smiles_embeddings_dict.joblib\")\n",
    "selfies_embeddings_path = os.path.join(\"data\", \"selfies_embeddings_dict.joblib\")\n",
    "smiles_tokens_embeddings_path = os.path.join(\n",
    "    \"data\", \"smiles_tokens_embeddings_dict.joblib\"\n",
    ")\n",
    "smiles_fingerprints_embeddings_path = os.path.join(\n",
    "    \"data\", \"smiles_fingerprints_embeddings_dict.joblib\"\n",
    ")\n",
    "\n",
    "ccl_ge_path = os.path.join(\"data\", \"ge_filtered_scaled.csv\")\n",
    "drp_test_path = os.path.join(\"data\", \"drp_test.csv\")\n",
    "drp_train_path = os.path.join(\"data\", \"drp_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drp_test_df = pd.read_csv(drp_test_path)\n",
    "len(drp_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selfies_test_unique = drp_test_df[\"selfies\"].unique()\n",
    "smiles_test_unique = drp_test_df[\"smiles\"].unique()\n",
    "print(f\"Number of unique selfies in test set: {len(selfies_test_unique)}\")\n",
    "print(f\"Number of unique smiles in test set: {len(smiles_test_unique)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"Average number of entries per unique selfies: {len(drp_test_df) / len(selfies_test_unique):.0f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_eval_metrics(model, test_loader, metrics, device, return_predictions=False):\n",
    "    \"\"\"\n",
    "    Compute evaluation metrics for a given model on a test dataset.\n",
    "    Optionally return predicted values and ground truth values.\n",
    "\n",
    "    Args:\n",
    "    - model (torch.nn.Module): The model to be evaluated.\n",
    "    - test_loader (DataLoader): DataLoader containing the test dataset.\n",
    "    - metrics (list of functions): List of metric functions to evaluate.\n",
    "    - device (torch.device): Device on which to perform the computations.\n",
    "    - return_predictions (bool): Whether to return predictions and ground truths.\n",
    "\n",
    "    Returns:\n",
    "    - List or Tuple: A list containing the computed metric values, and optionally, predictions and ground truths.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    all_outputs = []\n",
    "    all_labels = []\n",
    "    metric_results = [0] * len(metrics)\n",
    "    mse_losses = []\n",
    "\n",
    "    for batch in tqdm(test_loader):\n",
    "        with torch.no_grad():\n",
    "            cpd_emb = batch[\"cpd_embeddings\"].to(device)\n",
    "            ccl_emb = batch[\"ccl_ge_embeddings\"].to(device)\n",
    "            labels = batch[\"label\"].cpu()\n",
    "            outputs = model(cpd_emb, ccl_emb).cpu()\n",
    "\n",
    "            all_outputs.append(outputs)\n",
    "            all_labels.append(labels)\n",
    "\n",
    "            for i, metric in enumerate(metrics):\n",
    "                if metric.__name__ == \"mean_squared_error\":\n",
    "                    mse_loss = metric(outputs, labels).item()\n",
    "                    mse_losses.append(mse_loss)\n",
    "\n",
    "    all_outputs = torch.cat(all_outputs, dim=0)\n",
    "    all_labels = torch.cat(all_labels, dim=0)\n",
    "\n",
    "    for i, metric in enumerate(metrics):\n",
    "        if metric.__name__ == \"mean_squared_error\":\n",
    "            metric_results[i] = (np.mean(mse_losses), np.var(mse_losses))\n",
    "        else:\n",
    "            metric_results[i] = metric(all_outputs, all_labels).item()\n",
    "\n",
    "    if return_predictions:\n",
    "        return metric_results, all_outputs.numpy(), all_labels.numpy()\n",
    "    else:\n",
    "        return metric_results\n",
    "\n",
    "\n",
    "def compute_per_compound_metrics(\n",
    "    model, test_loader, metrics, device, return_predictions=False\n",
    "):\n",
    "    \"\"\"\n",
    "    Compute evaluation metrics for each compound in the test dataset.\n",
    "    Optionally return average predicted value, standard deviation of predicted values, \n",
    "    average ground truth value, and standard deviation of ground truth values per compound.\n",
    "\n",
    "    Args:\n",
    "    - model (torch.nn.Module): The model to be evaluated.\n",
    "    - test_loader (DataLoader): DataLoader containing the test dataset.\n",
    "    - metrics (list of functions): List of metric functions to evaluate.\n",
    "    - device (torch.device): Device on which to perform the computations.\n",
    "    - return_predictions (bool): Whether to return average predictions, prediction std,\n",
    "      average ground truths, and ground truth std per compound.\n",
    "\n",
    "    Returns:\n",
    "    - dict: A dictionary where keys are compound names and values are dictionaries of metric results,\n",
    "             and optionally, average predictions, prediction std, average ground truths,\n",
    "             and ground truth std per compound.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    compound_data = defaultdict(lambda: {\"outputs\": [], \"labels\": []})\n",
    "    compound_metrics = {}\n",
    "    predictions_dict = {} if return_predictions else None\n",
    "\n",
    "    for batch in tqdm(test_loader):\n",
    "        with torch.no_grad():\n",
    "            cpd_emb = batch[\"cpd_embeddings\"].to(device)\n",
    "            ccl_emb = batch[\"ccl_ge_embeddings\"].to(device)\n",
    "            labels = batch[\"label\"].cpu()\n",
    "            outputs = model(cpd_emb, ccl_emb).cpu()\n",
    "            cpd_names = batch[\"cpd_name\"]\n",
    "\n",
    "            for name, output, label in zip(cpd_names, outputs, labels):\n",
    "                compound_data[name][\"outputs\"].append(output.numpy())\n",
    "                compound_data[name][\"labels\"].append(label.numpy())\n",
    "\n",
    "    for cpd_name, data in compound_data.items():\n",
    "        cpd_outputs = np.array(data[\"outputs\"])\n",
    "        cpd_labels = np.array(data[\"labels\"])\n",
    "\n",
    "        avg_output = cpd_outputs.mean()\n",
    "        avg_label = cpd_labels.mean()\n",
    "        std_output = cpd_outputs.std()\n",
    "        std_label = cpd_labels.std()\n",
    "\n",
    "        if return_predictions:\n",
    "            predictions_dict[cpd_name] = {\n",
    "                \"outputs\": avg_output,\n",
    "                \"outputs_std\": std_output,\n",
    "                \"labels\": avg_label,\n",
    "                \"labels_std\": std_label\n",
    "            }\n",
    "\n",
    "        # Compute squared errors if MSE is one of the metrics\n",
    "        if any(metric.__name__ == \"mean_squared_error\" for metric in metrics):\n",
    "            squared_errors = (cpd_outputs - cpd_labels) ** 2\n",
    "            mse_mean = squared_errors.mean()\n",
    "            mse_std = squared_errors.std()\n",
    "            rmse = np.sqrt(mse_mean)\n",
    "        else:\n",
    "            mse_mean, mse_std, rmse = 0, 0, 0\n",
    "\n",
    "        compound_metrics[cpd_name] = {\n",
    "            \"mean_squared_error\": mse_mean,\n",
    "            \"root_mean_squared_error\": rmse,\n",
    "            \"std_of_squared_errors\": mse_std,\n",
    "        }\n",
    "\n",
    "        for metric in metrics:\n",
    "            if metric.__name__ != \"mean_squared_error\":\n",
    "                metric_value = metric(torch.from_numpy(cpd_outputs), torch.from_numpy(cpd_labels)).item()\n",
    "                compound_metrics[cpd_name][metric.__name__] = metric_value\n",
    "\n",
    "    if return_predictions:\n",
    "        return compound_metrics, predictions_dict\n",
    "    else:\n",
    "        return compound_metrics\n",
    "\n",
    "\n",
    "def plot_preds_vs_labels(\n",
    "    ground_truth, predictions, residuals=False, figsize=(8, 6), fontsize=14, title=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Create a plot with predicted values or residuals vs ground truth.\n",
    "\n",
    "    Args:\n",
    "    - ground_truth (array-like): Ground truth values.\n",
    "    - predictions (array-like): Predicted values.\n",
    "    - residuals (bool): Whether to plot residuals instead of predictions.\n",
    "    - figsize (tuple): Size of the figure.\n",
    "    - fontsize (int): Font size for labels and title.\n",
    "    - title (str): Title of the plot.\n",
    "    \"\"\"\n",
    "    with plt.style.context(\"seaborn-v0_8-whitegrid\"):\n",
    "        plt.figure(figsize=figsize)\n",
    "\n",
    "        y_axis_data = predictions if not residuals else ground_truth - predictions\n",
    "\n",
    "        plt.scatter(ground_truth, y_axis_data, alpha=0.5)\n",
    "\n",
    "        if residuals:\n",
    "            plt.axhline(y=0, color=\"r\", linestyle=\"--\", lw=2)\n",
    "            plt.ylabel(\"Residuals (Ground Truth - Predictions)\", fontsize=fontsize)\n",
    "        else:\n",
    "            plt.plot(\n",
    "                [ground_truth.min(), ground_truth.max()],\n",
    "                [ground_truth.min(), ground_truth.max()],\n",
    "                \"r--\",\n",
    "                lw=2,\n",
    "            )\n",
    "            plt.ylabel(\"Predictions\", fontsize=fontsize)\n",
    "\n",
    "        plt.xlabel(\"Ground Truth\", fontsize=fontsize)\n",
    "\n",
    "        if title is not None:\n",
    "            plt.title(title, fontsize=fontsize + 2)\n",
    "\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def plot_predictions_vs_ground_truth(\n",
    "    preds_dict,\n",
    "    figsize=(10, 6),\n",
    "    errorbar_color='lightgray',\n",
    "    errorbar_alpha=0.5,\n",
    "    point_color='blue',\n",
    "    line_color='k',\n",
    "    xlabel='Ground Truth Mean',\n",
    "    ylabel='Predicted Mean',\n",
    "    title='Predicted vs Ground Truth Values with Error Bars',\n",
    "    legend_loc='upper left',\n",
    "    fontsize=14\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot predicted values against ground truth values, including mean and standard deviation.\n",
    "\n",
    "    Args:\n",
    "    - preds_dict (dict): A dictionary where keys are compound names and values are dictionaries\n",
    "                         containing 'outputs', 'outputs_std', 'labels', and 'labels_std'.\n",
    "    - figsize (tuple): Size of the figure.\n",
    "    - errorbar_color (str): Color for the error bars.\n",
    "    - errorbar_alpha (float): Alpha transparency for the error bars.\n",
    "    - point_color (str): Color of the points.\n",
    "    - line_color (str): Color of the perfect predictions line.\n",
    "    - xlabel (str): Label for the x-axis.\n",
    "    - ylabel (str): Label for the y-axis.\n",
    "    - title (str): Title of the plot.\n",
    "    - legend_loc (str): Location of the legend.\n",
    "    - fontsize (int): Font size for labels, title, and legend.\n",
    "    \"\"\"\n",
    "    # Extracting data for plotting\n",
    "    compound_names = list(preds_dict.keys())\n",
    "    means = [preds_dict[cpd]['outputs'] for cpd in compound_names]\n",
    "    stds = [preds_dict[cpd]['outputs_std'] for cpd in compound_names]\n",
    "    ground_truths = [preds_dict[cpd]['labels'] for cpd in compound_names]\n",
    "    ground_truths_stds = [preds_dict[cpd]['labels_std'] for cpd in compound_names]\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.errorbar(\n",
    "        ground_truths, means, xerr=ground_truths_stds, yerr=stds, fmt='o', \n",
    "        ecolor=errorbar_color, elinewidth=2, alpha=errorbar_alpha, \n",
    "        color=point_color, label='Compounds'\n",
    "    )\n",
    "\n",
    "    # Line representing perfect predictions\n",
    "    min_val = min(min(ground_truths), min(means))\n",
    "    max_val = max(max(ground_truths), max(means))\n",
    "    plt.plot(\n",
    "        [min_val, max_val], [min_val, max_val], \n",
    "        linestyle='--', color=line_color, label='Perfect predictions'\n",
    "    )\n",
    "\n",
    "    plt.xlabel(xlabel, fontsize=fontsize)\n",
    "    plt.ylabel(ylabel, fontsize=fontsize)\n",
    "    plt.title(title, fontsize=fontsize + 2)\n",
    "    plt.legend(loc=legend_loc, fontsize=fontsize)\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def plot_ground_truth_distribution(\n",
    "    ground_truth_values,\n",
    "    ground_truth_values2=None,\n",
    "    bins=30,\n",
    "    show_kde=True,\n",
    "    figsize=(10, 6),\n",
    "    fontsize=14,\n",
    "    labels=[\"Set 1\", \"Set 2\"],\n",
    "    title=\"Distribution of Ground Truth Values\",\n",
    "    legend_loc=\"upper left\",\n",
    "    fill_alpha=0.5,\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot the distribution of ground truth values for all compounds. Optionally plot a second set of values on the same plot.\n",
    "\n",
    "    Args:\n",
    "    - ground_truth_values (array): Array of ground truth values.\n",
    "    - ground_truth_values2 (array, optional): Second array of ground truth values.\n",
    "    - figsize (tuple): Size of the figure.\n",
    "    - bins (int): Number of bins in the histogram.\n",
    "    - title (str): Title of the plot.\n",
    "    - fill_alpha (float): Opacity for the fill color.\n",
    "    - show_kde (bool): Whether to show the KDE line.\n",
    "    \"\"\"\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "\n",
    "    # Plot the first set of ground truth values\n",
    "    sns.histplot(\n",
    "        ground_truth_values,\n",
    "        bins=bins,\n",
    "        kde=show_kde,\n",
    "        stat=\"percent\",\n",
    "        label=labels[0],\n",
    "        element=\"step\",\n",
    "        fill=True,\n",
    "        alpha=fill_alpha,\n",
    "    )\n",
    "\n",
    "    # Plot the second set of ground truth values, if provided\n",
    "    if ground_truth_values2 is not None:\n",
    "        sns.histplot(\n",
    "            ground_truth_values2,\n",
    "            bins=bins,\n",
    "            kde=show_kde,\n",
    "            stat=\"percent\",\n",
    "            color=\"orange\",\n",
    "            label=labels[1],\n",
    "            element=\"step\",\n",
    "            fill=True,\n",
    "            alpha=fill_alpha,\n",
    "        )\n",
    "\n",
    "    plt.xlabel(\"Ground Truth Value\", fontsize=fontsize)\n",
    "    plt.ylabel(\"Percentage\", fontsize=fontsize)\n",
    "    plt.title(title, fontsize=fontsize + 2)\n",
    "    plt.legend(fontsize=fontsize, loc=legend_loc)\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def extract_labels_parallel(dataset, n_jobs=-1):\n",
    "    \"\"\"\n",
    "    Extract all label values and average label values per compound from a dataset using parallel processing.\n",
    "\n",
    "    Args:\n",
    "    - dataset (Dataset): The dataset to extract labels from.\n",
    "    - n_jobs (int): The number of jobs to run in parallel. -1 means using all processors.\n",
    "\n",
    "    Returns:\n",
    "    - tuple: A tuple containing two NumPy arrays:\n",
    "        1. An array of all label values.\n",
    "        2. An array of average label values per compound.\n",
    "    \"\"\"\n",
    "\n",
    "    def compute_average(labels):\n",
    "        \"\"\"Helper function to compute the average of a list of labels.\"\"\"\n",
    "        return np.mean(labels)\n",
    "\n",
    "    all_labels = []\n",
    "    compound_labels = defaultdict(list)\n",
    "\n",
    "    for entry in dataset:\n",
    "        label = entry[\"label\"].item()\n",
    "        compound_name = entry[\"cpd_name\"]\n",
    "\n",
    "        all_labels.append(label)\n",
    "        compound_labels[compound_name].append(label)\n",
    "\n",
    "    # Parallel computation of averages\n",
    "    avg_labels_per_compound = Parallel(n_jobs=n_jobs)(\n",
    "        delayed(compute_average)(labels) for labels in compound_labels.values()\n",
    "    )\n",
    "\n",
    "    return np.array(all_labels), np.array(avg_labels_per_compound)\n",
    "\n",
    "def percentage_values_in_range(values, low, high):\n",
    "    \"\"\"\n",
    "    Calculate the percentage of values within a specified range.\n",
    "\n",
    "    Args:\n",
    "    - values (array-like): The array of values to be filtered.\n",
    "    - low (float): The lower bound of the range.\n",
    "    - high (float): The upper bound of the range.\n",
    "\n",
    "    Returns:\n",
    "    - float: The percentage of values within the specified range.\n",
    "    \"\"\"\n",
    "    values_in_range = [value for value in values if low <= value < high]\n",
    "    percentage = (len(values_in_range) / len(values)) * 100\n",
    "    return percentage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of the 2D Embeddings Spaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SELFIES Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selfies_embeddings_dict = joblib.load(selfies_embeddings_path)\n",
    "\n",
    "selfies_embeddings = [value for value in selfies_embeddings_dict.values()]\n",
    "selfies_embeddings = np.array(selfies_embeddings)\n",
    "\n",
    "X = np.mean(selfies_embeddings, axis=1)\n",
    "\n",
    "tsne = TSNE()\n",
    "X_2d = tsne.fit_transform(X)\n",
    "\n",
    "test_indices = [\n",
    "    list(selfies_embeddings_dict.keys()).index(selfies)\n",
    "    for selfies in selfies_test_unique\n",
    "]\n",
    "\n",
    "with plt.style.context(\"seaborn-v0_8-whitegrid\"):\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.scatterplot(x=X_2d[:, 0], y=X_2d[:, 1], label=\"Train Embeddings\")\n",
    "    sns.scatterplot(\n",
    "        x=X_2d[test_indices, 0],\n",
    "        y=X_2d[test_indices, 1],\n",
    "        color=\"orange\",\n",
    "        label=\"Test Embeddings\",\n",
    "    )\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMILES Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles_embeddings_dict = joblib.load(smiles_embeddings_path)\n",
    "\n",
    "smiles_embeddings = [value for value in smiles_embeddings_dict.values()]\n",
    "smiles_embeddings = np.array(smiles_embeddings)\n",
    "\n",
    "X = np.mean(smiles_embeddings, axis=1)\n",
    "\n",
    "tsne = TSNE()\n",
    "X_2d = tsne.fit_transform(X)\n",
    "\n",
    "test_indices = [\n",
    "    list(smiles_embeddings_dict.keys()).index(smiles) for smiles in smiles_test_unique\n",
    "]\n",
    "\n",
    "with plt.style.context(\"seaborn-v0_8-whitegrid\"):\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.scatterplot(x=X_2d[:, 0], y=X_2d[:, 1], label=\"Train Embeddings\")\n",
    "    sns.scatterplot(\n",
    "        x=X_2d[test_indices, 0],\n",
    "        y=X_2d[test_indices, 1],\n",
    "        color=\"orange\",\n",
    "        label=\"Test Embeddings\",\n",
    "    )\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labels Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = DrugResponseDataset(\n",
    "    cpd_embeddings_path=selfies_embeddings_path,\n",
    "    ccl_ge_path=ccl_ge_path,\n",
    "    drp_path=drp_test_path,\n",
    "    cpd_type=\"selfies\",\n",
    ")\n",
    "\n",
    "train_dataset = DrugResponseDataset(\n",
    "    cpd_embeddings_path=selfies_embeddings_path,\n",
    "    ccl_ge_path=ccl_ge_path,\n",
    "    drp_path=drp_train_path,\n",
    "    cpd_type=\"selfies\",\n",
    ")\n",
    "\n",
    "test_all_labels, test_avg_label_values_per_compound = extract_labels_parallel(\n",
    "    test_dataset\n",
    ")\n",
    "train_all_labels, train_avg_label_values_per_compound = extract_labels_parallel(\n",
    "    train_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Per-compound distribution of label values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ground_truth_distribution(\n",
    "    test_avg_label_values_per_compound,\n",
    "    train_avg_label_values_per_compound,\n",
    "    show_kde=False,\n",
    "    bins=30,\n",
    "    figsize=(10, 6),\n",
    "    title=None,\n",
    "    labels=[\"Test Set\", \"Train Set\"],\n",
    "    fill_alpha=0.3,\n",
    "    legend_loc=\"upper left\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentage_values_in_range(train_avg_label_values_per_compound, 0, 0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-compound distribution of label values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ground_truth_distribution(\n",
    "    test_all_labels,\n",
    "    train_all_labels,\n",
    "    show_kde=False,\n",
    "    bins=30,\n",
    "    figsize=(10, 6),\n",
    "    title=None,\n",
    "    labels=[\"Test Set\", \"Train Set\"],\n",
    "    fill_alpha=0.3,\n",
    "    legend_loc=\"upper left\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Cross-Compounds Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SELFIES-based Trained Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DrugResponseDataset(\n",
    "    cpd_embeddings_path=selfies_embeddings_path,\n",
    "    ccl_ge_path=ccl_ge_path,\n",
    "    drp_path=drp_test_path,\n",
    "    cpd_type=\"selfies\",\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=256,\n",
    "    shuffle=False,\n",
    "    num_workers=8,\n",
    ")\n",
    "\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selfies_checkpoint = os.path.join(\n",
    "    \"checkpoints/selfies_model_20231127-053956/best_selfies_model_20231127-053956_trained.pt\"\n",
    ")\n",
    "selfies_state_dict = torch.load(selfies_checkpoint)\n",
    "\n",
    "selfies_model = DrugResponseModelLegacy(\n",
    "    cpd_sequence_length=256,\n",
    "    cpd_embedding_dim=768,\n",
    "    ccl_embedding_dim=6136,\n",
    "    hidden_dim=1020,\n",
    "    transformer_heads=6,\n",
    "    transformer_layers=6,\n",
    ").to(device)\n",
    "\n",
    "selfies_model.load_state_dict(selfies_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [mean_squared_error, pearson_corrcoef, spearman_corrcoef, mean_absolute_error]\n",
    "selfies_results, preds, labels = compute_eval_metrics(\n",
    "    selfies_model, test_loader, metrics, device, return_predictions=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"Mean Squared Error: {selfies_results[0][0]:.4f} +/- {selfies_results[0][1]:.4f}\"\n",
    ")\n",
    "print(f\"Mean Absolute Error: {selfies_results[3]:.4f}\")\n",
    "print(f\"Pearson Correlation: {selfies_results[1]:.4f}\")\n",
    "print(f\"Spearman Correlation: {selfies_results[2]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMILES-based Trained Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DrugResponseDataset(\n",
    "    cpd_embeddings_path=smiles_embeddings_path,\n",
    "    ccl_ge_path=ccl_ge_path,\n",
    "    drp_path=drp_test_path,\n",
    "    cpd_type=\"smiles\",\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=256,\n",
    "    shuffle=False,\n",
    "    num_workers=8,\n",
    ")\n",
    "\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles_checkpoint = os.path.join(\n",
    "    \"checkpoints/smiles_model_20231123-190031/best_smiles_model_20231123-190031_trained.pt\"\n",
    ")\n",
    "smiles_state_dict = torch.load(smiles_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles_model = DrugResponseModelLegacy(\n",
    "    cpd_sequence_length=256,\n",
    "    cpd_embedding_dim=768,\n",
    "    ccl_embedding_dim=6136,\n",
    "    hidden_dim=1020,\n",
    "    transformer_heads=6,\n",
    "    transformer_layers=6,\n",
    ").to(device)\n",
    "\n",
    "smiles_model.load_state_dict(smiles_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [mean_squared_error, pearson_corrcoef, spearman_corrcoef, mean_absolute_error]\n",
    "smiles_results, preds, labels = compute_eval_metrics(\n",
    "    smiles_model, test_loader, metrics, device, return_predictions=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Mean Squared Error: {smiles_results[0][0]:.4f} +/- {smiles_results[0][1]:.4f}\")\n",
    "print(f\"Mean Absolute Error: {smiles_results[3]:.4f}\")\n",
    "print(f\"Pearson Correlation: {smiles_results[1]:.4f}\")\n",
    "print(f\"Spearman Correlation: {smiles_results[2]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokens-based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DrugResponseDataset(\n",
    "    cpd_embeddings_path=smiles_tokens_embeddings_path,\n",
    "    ccl_ge_path=ccl_ge_path,\n",
    "    drp_path=drp_test_path,\n",
    "    cpd_type=\"smiles\",\n",
    "    embed_tokens=True,\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=256,\n",
    "    shuffle=False,\n",
    "    num_workers=8,\n",
    ")\n",
    "\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles_tokens_checkpoint = os.path.join(\n",
    "    \"checkpoints/smiles_tokens_model_20231204-183804/best_smiles_tokens_model_20231204-183804_trained.pt\"\n",
    ")\n",
    "smiles_tokens_state_dict = torch.load(smiles_tokens_checkpoint)\n",
    "\n",
    "smiles_tokens_model = DrugResponseModelTokens(\n",
    "    cpd_sequence_length=256,\n",
    "    cpd_embedding_dim=768,\n",
    "    ccl_embedding_dim=6136,\n",
    "    hidden_dim=1020,\n",
    "    transformer_heads=4,\n",
    "    transformer_layers=4,\n",
    ").to(device)\n",
    "\n",
    "smiles_tokens_model.load_state_dict(smiles_tokens_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [mean_squared_error, pearson_corrcoef, spearman_corrcoef, mean_absolute_error]\n",
    "smiles_tokens_results, smiles_tokens_preds, smiles_tokens_labels = compute_eval_metrics(\n",
    "    smiles_tokens_model, test_loader, metrics, device, return_predictions=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"Mean Squared Error: {smiles_tokens_results[0][0]:.4f} +/- {smiles_tokens_results[0][1]:.4f}\"\n",
    ")\n",
    "print(f\"Mean Absolute Error: {smiles_tokens_results[3]:.4f}\")\n",
    "print(f\"Pearson Correlation: {smiles_tokens_results[1]:.4f}\")\n",
    "print(f\"Spearman Correlation: {smiles_tokens_results[2]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fingerprints-based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DrugResponseDataset(\n",
    "    cpd_embeddings_path=smiles_fingerprints_embeddings_path,\n",
    "    ccl_ge_path=ccl_ge_path,\n",
    "    drp_path=drp_test_path,\n",
    "    cpd_type=\"smiles\",\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=256,\n",
    "    shuffle=False,\n",
    "    num_workers=8,\n",
    ")\n",
    "\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pl = DrugResponseLightningModule.load_from_checkpoint(\n",
    "    \"checkpoints/smiles_fingerprints_model_20231212-073658/epoch=119-val_loss=0.0003.ckpt\"\n",
    ")\n",
    "fingerprints_model = model_pl.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [mean_squared_error, pearson_corrcoef, spearman_corrcoef, mean_absolute_error]\n",
    "(\n",
    "    smiles_fingerprints_results,\n",
    "    smiles_fingerprints_preds,\n",
    "    smiles_fingerprints_labels,\n",
    ") = compute_eval_metrics(\n",
    "    fingerprints_model, test_loader, metrics, device, return_predictions=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"Mean Squared Error: {smiles_fingerprints_results[0][0]:.4f} +/- {smiles_fingerprints_results[0][1]:.4f}\"\n",
    ")\n",
    "print(f\"Mean Absolute Error: {smiles_fingerprints_results[3]:.4f}\")\n",
    "print(f\"Pearson Correlation: {smiles_fingerprints_results[1]:.4f}\")\n",
    "print(f\"Spearman Correlation: {smiles_fingerprints_results[2]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Per-compound evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SELFIES-based Trained Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = DrugResponseDataset(\n",
    "    cpd_embeddings_path=selfies_embeddings_path,\n",
    "    ccl_ge_path=ccl_ge_path,\n",
    "    drp_path=drp_test_path,\n",
    "    cpd_type=\"selfies\",\n",
    ")\n",
    "\n",
    "train_dataset = DrugResponseDataset(\n",
    "    cpd_embeddings_path=selfies_embeddings_path,\n",
    "    ccl_ge_path=ccl_ge_path,\n",
    "    drp_path=drp_train_path,\n",
    "    cpd_type=\"selfies\",\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=256,\n",
    "    shuffle=False,\n",
    "    num_workers=8,\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=256,\n",
    "    shuffle=False,\n",
    "    num_workers=8,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selfies_checkpoint = os.path.join(\n",
    "    \"checkpoints/selfies_model_20231127-053956/best_selfies_model_20231127-053956_trained.pt\"\n",
    ")\n",
    "selfies_state_dict = torch.load(selfies_checkpoint)\n",
    "\n",
    "selfies_model = DrugResponseModelLegacy(\n",
    "    cpd_sequence_length=256,\n",
    "    cpd_embedding_dim=768,\n",
    "    ccl_embedding_dim=6136,\n",
    "    hidden_dim=1020,\n",
    "    transformer_heads=6,\n",
    "    transformer_layers=6,\n",
    ").to(device)\n",
    "\n",
    "selfies_model.load_state_dict(selfies_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [mean_squared_error, pearson_corrcoef, spearman_corrcoef]\n",
    "(\n",
    "    test_selfies_results,\n",
    "    test_per_compound_preds_selfies,\n",
    ") = compute_per_compound_metrics(\n",
    "    selfies_model, test_loader, metrics, device, return_predictions=True\n",
    ")\n",
    "\n",
    "(\n",
    "    train_seflies_results,\n",
    "    train_per_compound_preds_selfies,\n",
    ") = compute_per_compound_metrics(\n",
    "    selfies_model, train_loader, metrics, device, return_predictions=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictions_vs_ground_truth(test_per_compound_preds_selfies, title=None, xlabel='Mean Ground Truth AUC Value', ylabel='Mean Predicted AUC Value', fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictions_vs_ground_truth(train_per_compound_preds_selfies, title=None, xlabel='Mean Ground Truth AUC Value', ylabel='Mean Predicted AUC Value', fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMILES-based Trained Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = DrugResponseDataset(\n",
    "    cpd_embeddings_path=smiles_embeddings_path,\n",
    "    ccl_ge_path=ccl_ge_path,\n",
    "    drp_path=drp_test_path,\n",
    "    cpd_type=\"smiles\",\n",
    ")\n",
    "\n",
    "train_dataset = DrugResponseDataset(\n",
    "    cpd_embeddings_path=smiles_embeddings_path,\n",
    "    ccl_ge_path=ccl_ge_path,\n",
    "    drp_path=drp_train_path,\n",
    "    cpd_type=\"smiles\",\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=256,\n",
    "    shuffle=False,\n",
    "    num_workers=8,\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=256,\n",
    "    shuffle=False,\n",
    "    num_workers=8,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles_checkpoint = os.path.join(\n",
    "    \"checkpoints/smiles_model_20231123-190031/best_smiles_model_20231123-190031_trained.pt\"\n",
    ")\n",
    "smiles_state_dict = torch.load(smiles_checkpoint)\n",
    "\n",
    "smiles_model = DrugResponseModelLegacy(\n",
    "    cpd_sequence_length=256,\n",
    "    cpd_embedding_dim=768,\n",
    "    ccl_embedding_dim=6136,\n",
    "    hidden_dim=1020,\n",
    "    transformer_heads=6,\n",
    "    transformer_layers=6,\n",
    ").to(device)\n",
    "\n",
    "smiles_model.load_state_dict(smiles_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [mean_squared_error, pearson_corrcoef, spearman_corrcoef]\n",
    "(\n",
    "    test_smiles_results,\n",
    "    test_per_compound_preds_smiles,\n",
    ") = compute_per_compound_metrics(\n",
    "    smiles_model, test_loader, metrics, device, return_predictions=True\n",
    ")\n",
    "\n",
    "(\n",
    "    train_smiles_results,\n",
    "    train_per_compound_preds_smiles,\n",
    ") = compute_per_compound_metrics(\n",
    "    smiles_model, train_loader, metrics, device, return_predictions=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictions_vs_ground_truth(test_per_compound_preds_smiles, title=None, xlabel='Mean Ground Truth AUC Value', ylabel='Mean Predicted AUC Value', fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictions_vs_ground_truth(train_per_compound_preds_smiles, title=None, xlabel='Mean Ground Truth AUC Value', ylabel='Mean Predicted AUC Value', fontsize=14)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Token-based model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = DrugResponseDataset(\n",
    "    cpd_embeddings_path=smiles_tokens_embeddings_path,\n",
    "    ccl_ge_path=ccl_ge_path,\n",
    "    drp_path=drp_test_path,\n",
    "    cpd_type=\"smiles\",\n",
    "    embed_tokens=True,\n",
    ")\n",
    "\n",
    "train_dataset = DrugResponseDataset(\n",
    "    cpd_embeddings_path=smiles_tokens_embeddings_path,\n",
    "    ccl_ge_path=ccl_ge_path,\n",
    "    drp_path=drp_train_path,\n",
    "    cpd_type=\"smiles\",\n",
    "    embed_tokens=True,\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=256,\n",
    "    shuffle=False,\n",
    "    num_workers=8,\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=256,\n",
    "    shuffle=False,\n",
    "    num_workers=8,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles_tokens_checkpoint = os.path.join(\n",
    "    \"checkpoints/smiles_tokens_model_20231204-183804/best_smiles_tokens_model_20231204-183804_trained.pt\"\n",
    ")\n",
    "smiles_tokens_state_dict = torch.load(smiles_tokens_checkpoint)\n",
    "\n",
    "smiles_tokens_model = DrugResponseModelTokens(\n",
    "    cpd_sequence_length=256,\n",
    "    cpd_embedding_dim=768,\n",
    "    ccl_embedding_dim=6136,\n",
    "    hidden_dim=1020,\n",
    "    transformer_heads=4,\n",
    "    transformer_layers=4,\n",
    ").to(device)\n",
    "\n",
    "smiles_tokens_model.load_state_dict(smiles_tokens_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [mean_squared_error, pearson_corrcoef, spearman_corrcoef]\n",
    "(\n",
    "    test_smiles_tokens_results,\n",
    "    test_per_compound_preds_tokens,\n",
    ") = compute_per_compound_metrics(\n",
    "    smiles_tokens_model, test_loader, metrics, device, return_predictions=True\n",
    ")\n",
    "\n",
    "(\n",
    "    train_smiles_tokens_results,\n",
    "    train_per_compound_preds_tokens,\n",
    ") = compute_per_compound_metrics(\n",
    "    smiles_tokens_model, train_loader, metrics, device, return_predictions=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictions_vs_ground_truth(test_per_compound_preds_tokens, title=None, xlabel='Mean Ground Truth AUC Value', ylabel='Mean Predicted AUC Value', fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictions_vs_ground_truth(train_per_compound_preds_tokens, title=None, xlabel='Mean Ground Truth AUC Value', ylabel='Mean Predicted AUC Value', fontsize=14)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Morgan Fingerprints based model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = DrugResponseDataset(\n",
    "    cpd_embeddings_path=smiles_fingerprints_embeddings_path,\n",
    "    ccl_ge_path=ccl_ge_path,\n",
    "    drp_path=drp_test_path,\n",
    "    cpd_type=\"smiles\",\n",
    ")\n",
    "\n",
    "train_dataset = DrugResponseDataset(\n",
    "    cpd_embeddings_path=smiles_fingerprints_embeddings_path,\n",
    "    ccl_ge_path=ccl_ge_path,\n",
    "    drp_path=drp_train_path,\n",
    "    cpd_type=\"smiles\",\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=256,\n",
    "    shuffle=False,\n",
    "    num_workers=8,\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=256,\n",
    "    shuffle=False,\n",
    "    num_workers=8,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pl = DrugResponseLightningModule.load_from_checkpoint(\n",
    "    \"checkpoints/smiles_fingerprints_model_20231212-073658/epoch=119-val_loss=0.0003.ckpt\"\n",
    ")\n",
    "fingerprints_model = model_pl.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [mean_squared_error, pearson_corrcoef, spearman_corrcoef]\n",
    "(\n",
    "    test_smiles_fingerprints_results,\n",
    "    test_per_compound_preds_fingerprints,\n",
    ") = compute_per_compound_metrics(\n",
    "    fingerprints_model, test_loader, metrics, device, return_predictions=True\n",
    ")\n",
    "\n",
    "(\n",
    "    train_smiles_fingerprints_results,\n",
    "    train_per_compound_preds_fingerprints,\n",
    ") = compute_per_compound_metrics(\n",
    "    fingerprints_model, train_loader, metrics, device, return_predictions=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictions_vs_ground_truth(test_per_compound_preds_fingerprints, title=None, xlabel='Mean Ground Truth AUC Value', ylabel='Mean Predicted AUC Value', fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictions_vs_ground_truth(train_per_compound_preds_fingerprints, title=None, xlabel='Mean Ground Truth AUC Value', ylabel='Mean Predicted AUC Value', fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Training and Validation Curves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot all the training and validation curves on the same plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selfies_training_loss_1 = os.path.join(\n",
    "    \"data/training_results/selfies_selfies_model_20231124-092533_selfies_model_version_0.csv\"\n",
    ")\n",
    "selfies_training_loss_2 = os.path.join(\n",
    "    \"data/training_results/selfies_selfies_model_20231127-053956_selfies_model_version_0.csv\"\n",
    ")\n",
    "selfies_training_loss_1_df = pd.read_csv(selfies_training_loss_1)\n",
    "selfies_training_loss_2_df = pd.read_csv(selfies_training_loss_2)\n",
    "selfies_training_loss_df = pd.concat(\n",
    "    [selfies_training_loss_1_df, selfies_training_loss_2_df]\n",
    ")\n",
    "\n",
    "selfies_val_loss_1 = os.path.join(\n",
    "    \"data/training_results/selfies_selfies_model_20231124-092533_selfies_model_version_0_val.csv\"\n",
    ")\n",
    "selfies_val_loss_2 = os.path.join(\n",
    "    \"data/training_results/selfies_selfies_model_20231127-053956_selfies_model_version_0_val.csv\"\n",
    ")\n",
    "selfies_val_loss_1_df = pd.read_csv(selfies_val_loss_1)\n",
    "selfies_val_loss_2_df = pd.read_csv(selfies_val_loss_2)\n",
    "selfies_val_loss_df = pd.concat([selfies_val_loss_1_df, selfies_val_loss_2_df])\n",
    "\n",
    "smiles_training_loss = os.path.join(\n",
    "    \"data/training_results/smiles_smiles_model_20231123-190031_smiles_model_version_0.csv\"\n",
    ")\n",
    "smiles_val_loss = os.path.join(\n",
    "    \"data/training_results/smiles_smiles_model_20231123-190031_smiles_model_version_0_val.csv\"\n",
    ")\n",
    "smiles_training_loss_df = pd.read_csv(smiles_training_loss)\n",
    "smiles_val_loss_df = pd.read_csv(smiles_val_loss)\n",
    "\n",
    "smiles_tokens_training_loss = os.path.join(\n",
    "    \"data/training_results/smiles_tokens_smiles_tokens_model_20231204-183804_smiles_tokens_model_version_0.csv\"\n",
    ")\n",
    "smiles_tokens_val_loss = os.path.join(\n",
    "    \"data/training_results/smiles_tokens_smiles_tokens_model_20231204-183804_smiles_tokens_model_version_0_val.csv\"\n",
    ")\n",
    "smiles_tokens_training_loss_df = pd.read_csv(smiles_tokens_training_loss)\n",
    "smiles_tokens_val_loss_df = pd.read_csv(smiles_tokens_val_loss)\n",
    "\n",
    "fingerprints_training_loss = os.path.join(\n",
    "    \"data/training_results/fingerprints_smiles_fingerprints_model_20231212-073658_smiles_fingerprints_model_version_0.csv\"\n",
    ")\n",
    "fingerprints_val_loss = os.path.join(\n",
    "    \"data/training_results/fingerprints_smiles_fingerprints_model_20231212-073658_smiles_fingerprints_model_version_0_val.csv\"\n",
    ")\n",
    "fingerprints_training_loss_df = pd.read_csv(fingerprints_training_loss)\n",
    "fingerprints_val_loss_df = pd.read_csv(fingerprints_val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.style.context(\"seaborn-v0_8-whitegrid\"):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(\n",
    "        selfies_training_loss_df[\"Step\"],\n",
    "        selfies_training_loss_df[\"Value\"],\n",
    "        label=\"SELFIES Embeddings\",\n",
    "    )\n",
    "    plt.plot(\n",
    "        smiles_training_loss_df[\"Step\"],\n",
    "        smiles_training_loss_df[\"Value\"],\n",
    "        label=\"SMILES Embeddings\",\n",
    "    )\n",
    "    plt.plot(\n",
    "        smiles_tokens_training_loss_df[\"Step\"],\n",
    "        smiles_tokens_training_loss_df[\"Value\"],\n",
    "        label=\"SMILES Tokens\",\n",
    "    )\n",
    "    plt.plot(\n",
    "        fingerprints_training_loss_df[\"Step\"],\n",
    "        fingerprints_training_loss_df[\"Value\"],\n",
    "        label=\"Morgan Fingerprints\",\n",
    "    )\n",
    "    plt.xlabel(\"Steps\", fontsize=14)\n",
    "    plt.ylabel(\"MSE Loss\", fontsize=14)\n",
    "    # plt.title(\"Training Losses\", fontsize=16)\n",
    "    plt.ylim(0, 0.06)\n",
    "    plt.legend(fontsize=14)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.style.context(\"seaborn-v0_8-whitegrid\"):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(\n",
    "        selfies_val_loss_df[\"Step\"],\n",
    "        selfies_val_loss_df[\"Value\"],\n",
    "        label=\"SELFIES Embeddings\",\n",
    "    )\n",
    "    plt.plot(\n",
    "        smiles_val_loss_df[\"Step\"],\n",
    "        smiles_val_loss_df[\"Value\"],\n",
    "        label=\"SMILES Embeddings\",\n",
    "    )\n",
    "    plt.plot(\n",
    "        smiles_tokens_val_loss_df[\"Step\"],\n",
    "        smiles_tokens_val_loss_df[\"Value\"],\n",
    "        label=\"SMILES Tokens\",\n",
    "    )\n",
    "    plt.plot(\n",
    "        fingerprints_val_loss_df[\"Step\"],\n",
    "        fingerprints_val_loss_df[\"Value\"],\n",
    "        label=\"Morgan Fingerprints\",\n",
    "    )\n",
    "    plt.xlabel(\"Steps\", fontsize=14)\n",
    "    plt.ylabel(\"MSE Loss\", fontsize=14)\n",
    "    # plt.title(\"Validation Losses\", fontsize=16)\n",
    "    plt.ylim(0, 0.06)\n",
    "    plt.legend(fontsize=14)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
