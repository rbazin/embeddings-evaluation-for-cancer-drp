{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SELFIES embeddings precomputation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we precompute all of the embeddings for the SMILES in our train and test sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading SELFormer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import json\n",
    "\n",
    "from transformers import RobertaTokenizer, RobertaModel, RobertaConfig\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device : {device}\")\n",
    "os.chdir(\"/home/python/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"./SELFormer/data/pretrained_models/modelO\" # path of the pre-trained model\n",
    "\n",
    "config = RobertaConfig.from_pretrained(model_name)\n",
    "config.output_hidden_states = True\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"./SELFormer/data/RobertaFastTokenizer\")\n",
    "model = RobertaModel.from_pretrained(model_name, config=config).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating SELFIES embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_embeddings(selfies):\n",
    "    selfies_tokens = tokenizer(selfies, add_special_tokens=True, max_length=256, padding='max_length', truncation=True, return_tensors=\"pt\")\n",
    "    dataset = TensorDataset(selfies_tokens.input_ids, selfies_tokens.attention_mask)\n",
    "    dataloader = DataLoader(dataset, batch_size=24, shuffle=False, num_workers=2)\n",
    "\n",
    "    embeddings = []\n",
    "    for i, batch in enumerate(tqdm(dataloader)):\n",
    "\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask = batch\n",
    "\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            selfies_embeddings = model(input_ids=b_input_ids, attention_mask=b_input_mask)\n",
    "        \n",
    "        last_hidden_states = selfies_embeddings.last_hidden_state\n",
    "        \n",
    "        embeddings.append(last_hidden_states.cpu().numpy())\n",
    "\n",
    "    embeddings_np = np.concatenate(embeddings, axis=0)\n",
    "\n",
    "    return embeddings_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/data/drp.csv\") # path of the selfies data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selfies = list(np.unique(df[\"selfies\"].values))\n",
    "len(selfies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selfies_embeddings = compute_embeddings(selfies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compound_embeddings_dict = {selfies: embedding for selfies, embedding in zip(selfies, list(selfies_embeddings))}\n",
    "compound_embeddings_dict[selfies[0]].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(compound_embeddings_dict, os.path.join(\"./data\", \"data\", \"selfies_embeddings_dict.joblib\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.load(os.path.join(\"./data\", \"data\", \"selfies_embeddings_dict.joblib\"))[selfies[0]].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
