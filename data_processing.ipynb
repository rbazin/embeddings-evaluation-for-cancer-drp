{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading both datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Depmap cancer cell lines omics data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metadata file\n",
    "meta_df = pd.read_csv(os.path.join(\"data\", \"Model.csv\"), header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_df.loc[:10, [\"ModelID\", \"StrippedCellLineName\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Omics datafile for cancer cell lines\n",
    "genes_expressions_path = os.path.join(\n",
    "    \"data\", \"OmicsExpressionProteinCodingGenesTPMLogp1.csv\"\n",
    ")\n",
    "ge_df = pd.read_csv(genes_expressions_path, header=0)\n",
    "ge_df.rename(columns={\"Unnamed: 0\": \"ModelID\"}, inplace=True)\n",
    "ge_df.loc[:10, [\"ModelID\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ge_names = list(ge_df.columns)\n",
    "ge_names.remove(\"ModelID\")\n",
    "ge_names[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge metadata and omics data\n",
    "ge_df = pd.merge(meta_df, ge_df, how=\"inner\", on=\"ModelID\")\n",
    "ge_df.loc[:10, [\"ModelID\", \"StrippedCellLineName\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ge_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ge_df.drop(\n",
    "    [k for k in ge_df.columns if k not in [*ge_names, \"StrippedCellLineName\"]],\n",
    "    axis=1,\n",
    "    inplace=True,\n",
    ")\n",
    "ge_df.rename(columns={\"StrippedCellLineName\": \"ccl_name\"}, inplace=True)\n",
    "ge_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ge_df.to_csv(os.path.join(\"data\", \"ge.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CTRPv2 DRP experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drp_data = pd.read_csv(\n",
    "    os.path.join(\"data\", \"CTRPv2\", \"v21.data.auc_sensitivities.txt\"), sep=\"\\t\", header=0\n",
    ")\n",
    "drp_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_cell_lines = pd.read_csv(\n",
    "    os.path.join(\"data\", \"CTRPv2\", \"v21.meta.per_cell_line.txt\"),\n",
    "    sep=\"\\t\",\n",
    "    header=0,\n",
    "    usecols=[\"ccl_name\", \"master_ccl_id\"],\n",
    ")\n",
    "meta_cell_lines.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(meta_cell_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_compounds = pd.read_csv(\n",
    "    os.path.join(\"data\", \"CTRPv2\", \"v21.meta.per_compound.txt\"),\n",
    "    sep=\"\\t\",\n",
    "    header=0,\n",
    "    usecols=[\"cpd_smiles\", \"master_cpd_id\"],\n",
    ")\n",
    "meta_compounds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(meta_compounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge drp data with meta compounds and meta cell lines\n",
    "drp_data = drp_data.merge(\n",
    "    meta_cell_lines, left_on=\"master_ccl_id\", right_on=\"master_ccl_id\", how=\"left\"\n",
    ")\n",
    "drp_data = drp_data.merge(\n",
    "    meta_compounds, left_on=\"master_cpd_id\", right_on=\"master_cpd_id\", how=\"left\"\n",
    ")\n",
    "drp_data.drop([\"master_ccl_id\", \"master_cpd_id\", \"experiment_id\"], axis=1, inplace=True)\n",
    "drp_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(drp_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drp_data.to_csv(os.path.join(\"data\", \"drp.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing diff in ccl_names between DRP and GE datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When exploring both the DRP and GE datasets, we noted that certain cell lines were appearing in the DRP dataset but not in the GE dataset.\n",
    "\n",
    "As they represent a very marginal fraction of the total number of cell lines tested, we decided to drop them from the DRP dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ge_df = pd.read_csv(os.path.join(\"data\", \"ge.csv\"), header=0, index_col=0)\n",
    "drp_df = pd.read_csv(os.path.join(\"data\", \"drp.csv\"), header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drp_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccl_names_drp = list(drp_df['ccl_name'].unique())\n",
    "ccl_names_ge = list(ge_df.index.unique())\n",
    "ccl_names_diff = list(set(ccl_names_drp) - set(ccl_names_ge))\n",
    "print(len(ccl_names_diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drp_df.drop(drp_df[drp_df['ccl_name'].isin(ccl_names_diff)].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drp_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drp_df.to_csv(os.path.join(\"data\", \"drp.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMILES to SELFIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import selfies as sf\n",
    "import joblib\n",
    "from joblib import Parallel, delayed\n",
    "from multiprocessing import cpu_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating selfies for train set :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drp_df = pd.read_csv(os.path.join(\"data\", \"drp.csv\"), header=0)\n",
    "drp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "def apply_func_to_chunk(chunk, func):\n",
    "    try:\n",
    "        chunk['cpd_selfies'] = chunk['cpd_smiles'].apply(func)\n",
    "        return chunk\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return chunk\n",
    "\n",
    "def parallel_apply(df, func, column):\n",
    "    num_cores = joblib.cpu_count()\n",
    "    df_split = np.array_split(df, num_cores)\n",
    "\n",
    "    results = Parallel(n_jobs=num_cores)(delayed(apply_func_to_chunk)(chunk, func) for chunk in df_split)\n",
    "\n",
    "    df = pd.concat(results)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drp_df = parallel_apply(drp_df, sf.encoder, 'cpd_smiles') # parallel apply if possible\n",
    "# drp_df['cpd_selfies'] = drp_df['cpd_smiles'].apply(sf.encoder) # if not possible\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(drp_df))\n",
    "drp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drp_df.rename(columns={\"cpd_smiles\": \"smiles\", \"cpd_selfies\" : \"selfies\"}, inplace=True)\n",
    "drp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drp_df.to_csv(os.path.join(\"data\", \"drp.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMILES to Morgan Fingerprints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drp_df = pd.read_csv(os.path.join(\"data\", \"drp.csv\"), header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles_unique = list(np.unique(drp_df[\"smiles\"].values))\n",
    "print(f\"Number of unique smiles: {len(smiles_unique)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles_unique[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bit={}\n",
    "smiles_fingerprints = []\n",
    "for smiles in smiles_unique:\n",
    "    m = Chem.MolFromSmiles(smiles)\n",
    "    fp = AllChem.GetMorganFingerprintAsBitVect(m,useChirality=True, radius=3, nBits = 2048, bitInfo=bit)\n",
    "    smiles_fingerprints.append(np.array(fp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(smiles_fingerprints), smiles_fingerprints[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compound_embeddings_dict = {s: embedding for s, embedding in zip(smiles_unique, smiles_fingerprints)}\n",
    "compound_embeddings_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(compound_embeddings_dict, os.path.join(\"data\", \"smiles_fingerprints_embeddings_dict.joblib\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_embeddings_presence(drp_path, embeddings_dict_path):\n",
    "    drp_df = pd.read_csv(drp_path, header=0)\n",
    "    embeddings_dict = joblib.load(embeddings_dict_path)\n",
    "\n",
    "    smiles_unique = set(drp_df[\"smiles\"].values)\n",
    "    smiles_embeddings = set(embeddings_dict.keys())\n",
    "    print(f\"Number of unique smiles: {len(smiles_unique)}\")\n",
    "    print(f\"Number of smiles in embeddings_dict: {len(smiles_embeddings)}\")\n",
    "    \n",
    "    return True if smiles_unique.issubset(smiles_embeddings) else False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_embeddings_presence(os.path.join(\"data\", \"drp_train.csv\"), os.path.join(\"data\", \"smiles_fingerprints_embeddings_dict.joblib\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting DRP data in train and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to take a drug-blind evaluation approach, which entails keeping a number of drugs unseen to the model during training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix the seed\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drp_df = pd.read_csv(os.path.join(\"data\", \"drp.csv\"), header=0)\n",
    "smiles = drp_df[\"smiles\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(smiles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(smiles))\n",
    "test_size = len(smiles) - train_size\n",
    "print(f\"Number of training compounds : {train_size}\")\n",
    "print(f\"Number of test compounds : {test_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_compounds, test_compounds = train_test_split(\n",
    "    smiles,\n",
    "    train_size=train_size,\n",
    "    test_size=test_size,\n",
    "    random_state=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drp_train = drp_df[drp_df['smiles'].isin(train_compounds)]\n",
    "drp_test = drp_df[drp_df['smiles'].isin(test_compounds)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(drp_train), len(drp_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save all dfs to disk\n",
    "drp_train.to_csv(os.path.join(\"data\", \"drp_train.csv\"), index=False)\n",
    "drp_test.to_csv(os.path.join(\"data\", \"drp_test.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GE filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gene expressions taken from Depmap dataset are already partially preprocessed.\n",
    "\n",
    "Here we will only remove the gene expressions with low variance (<1), which we will hypothetize to have low importance in the cancer biological processes.\n",
    "\n",
    "The variance will be computed on the train set only to prevent any data leakage to the test set. Then the selection obtained from the train set will be applied to the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "from joblib import Parallel, delayed\n",
    "from multiprocessing import cpu_count\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_chunk(chunk, threshold):\n",
    "    variances = chunk.var(axis=0)\n",
    "    return variances.index[variances >= threshold].tolist()\n",
    "\n",
    "def filter_low_variance_genes_large_dataset(filepath, threshold: float = 1.0) -> List[str]:\n",
    "    chunk_size = 10 ** 4\n",
    "    chunks = pd.read_csv(filepath, chunksize=chunk_size, index_col=0, header=0)\n",
    "    \n",
    "    results = Parallel(n_jobs=cpu_count())(delayed(process_chunk)(chunk, threshold) for chunk in chunks)\n",
    "    \n",
    "    columns_to_keep = list(set().union(*results))\n",
    "    return columns_to_keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ge_path = os.path.join(\"data\", \"ge.csv\")\n",
    "columns_to_keep = filter_low_variance_genes_large_dataset(ge_path, threshold=1.0)\n",
    "print(len(columns_to_keep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ge_filtered = pd.read_csv(ge_path, usecols=['ccl_name', *columns_to_keep], header=0, index_col=0)\n",
    "ge_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ge_filtered.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ge_filtered.to_csv(os.path.join(\"data\", \"ge_filtered.csv\"), index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(columns_to_keep, os.path.join(\"data\", \"list_genes_filtered.joblib\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's normalize both the AUC label score and the GE features of the train set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GE Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ge_filtered_df = pd.read_csv(os.path.join(\"data\", \"ge_filtered.csv\"), header=0, index_col=0)\n",
    "ge_filtered_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ge_filtered_df.values\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = StandardScaler() # Normal distribution, preserves outliers that may be way past [-1, 1]\n",
    "scaler = MinMaxScaler((-1, 1)) # fit between -1 and 1, preserves outliers\n",
    "normalized_data = scaler.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dataset with scaled features\n",
    "ge_filtered_scaled_df = ge_filtered_df.copy()\n",
    "ge_filtered_scaled_df.iloc[:, :] = normalized_data\n",
    "ge_filtered_scaled_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dataset with scaled features\n",
    "ge_filtered_scaled_df.to_csv(os.path.join(\"data\", \"ge_filtered_scaled.csv\"), index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the scaler checkpoint\n",
    "joblib.dump(scaler, os.path.join(\"data\", \"scaler_checkpoints\", \"ge_scaler.joblib\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AUC Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drp_train_df = pd.read_csv(os.path.join(\"data\", \"drp_train.csv\"), header=0)\n",
    "drp_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_values = drp_train_df[\"area_under_curve\"].values\n",
    "auc_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = StandardScaler() # Normal distribution, preserves outliers that may be way past [-1, 1]\n",
    "scaler = MinMaxScaler((-1, 1)) # fit between -1 and 1, preserves outliers\n",
    "normalized_data = scaler.fit_transform(auc_values.reshape(-1, 1)).squeeze()\n",
    "normalized_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drp_train_df[\"area_under_curve_scaled\"] = normalized_data\n",
    "drp_train_df = drp_train_df[[\"area_under_curve\", \"area_under_curve_scaled\", \"ccl_name\", \"smiles\", \"selfies\"]]\n",
    "drp_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dataset with scaled features\n",
    "drp_train_df.to_csv(os.path.join(\"data\", \"drp_train.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the transformation to the test set\n",
    "drp_test_df = pd.read_csv(os.path.join(\"data\", \"drp_test.csv\"), header=0)\n",
    "drp_test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_values = drp_test_df[\"area_under_curve\"].values\n",
    "auc_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_data = scaler.transform(auc_values.reshape(-1, 1)).squeeze()\n",
    "normalized_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drp_test_df[\"area_under_curve_scaled\"] = normalized_data\n",
    "drp_test_df = drp_test_df[[\"area_under_curve\", \"area_under_curve_scaled\", \"ccl_name\", \"smiles\", \"selfies\"]]\n",
    "drp_test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drp_test_df.to_csv(os.path.join(\"data\", \"drp_test.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the scaler checkpoint\n",
    "joblib.dump(scaler, os.path.join(\"data\", \"scaler_checkpoints\", \"drp_scaler.joblib\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking Nan and Inf values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GE dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ge_df = pd.read_csv(os.path.join(\"data\", \"ge_filtered_scaled.csv\"), header=0, index_col=0)\n",
    "ge_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ge_df.isna().any().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test inf values\n",
    "ge_df[ge_df == np.inf].any().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test -inf values\n",
    "ge_df[ge_df == -np.inf].any().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test value range\n",
    "ge_df.max().max(), ge_df.min().min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like they are huge outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute mean and std of each column then check if there are which are not 1 and 0\n",
    "ge_df.mean().mean(), ge_df.std().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DRP dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drp_df = pd.read_csv(os.path.join(\"data\", \"drp_train.csv\"), header=0)\n",
    "drp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_values = drp_df[\"area_under_curve_scaled\"]\n",
    "auc_values.max(), auc_values.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_values.mean(), auc_values.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_values.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.displot(auc_values, kde=True, height=8, aspect=2)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
